{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6c4f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb1085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Evaluations\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"Evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c18031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    " \n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question_with_llm(llm):\n",
    "    loader = PyMuPDFLoader(\"SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    split_documents = text_splitter.split_documents(docs)\n",
    "    \n",
    "    embeddings = UpstageEmbeddings(model=\"embedding-query\")\n",
    "    vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"You are an assistant for question-answering tasks. \n",
    "        Use the following pieces of retrieved context to answer the question. \n",
    "        If you don't know the answer, just say that you don't know. \n",
    "        Answer in Korean.\n",
    "\n",
    "        #Question: \n",
    "        {question} \n",
    "        #Context: \n",
    "        {context} \n",
    "\n",
    "        #Answer:\"\"\"\n",
    "    )   \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    def _ask_question(inputs: dict):\n",
    "        # 질문에 대한 컨텍스트 검색\n",
    "        context = retriever.invoke(inputs[\"question\"])\n",
    "        # 검색된 문서들을 하나의 문자열로 결합\n",
    "        context = \"\\n\".join([doc.page_content for doc in context])\n",
    "        # 질문, 컨텍스트, 답변을 포함한 딕셔너리 반환\n",
    "        return {\n",
    "            \"question\": inputs[\"question\"],\n",
    "            \"context\": context,\n",
    "            \"answer\": rag_chain.invoke(inputs[\"question\"]),\n",
    "        }\n",
    "\n",
    "    return _ask_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f9d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatUpstage(model=\"solar-mini\")\n",
    "\n",
    "upstage_chain = ask_question_with_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78b8697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "# 업스테이지 Groundness Checker 생성\n",
    "upstage_groundedness_check = UpstageGroundednessCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba44aac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n"
     ]
    }
   ],
   "source": [
    "# Groundness Checker 를 실행하여 평가\n",
    "request_input = {\n",
    "    \"context\": \"테디의 성별은 남자이며, 테디노트 유튜브 채널을 운영하고 있습니다.\",\n",
    "    \"answer\": \"테디는 남자다.\",\n",
    "}\n",
    "\n",
    "response = upstage_groundedness_check.invoke(request_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367f9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notGrounded\n"
     ]
    }
   ],
   "source": [
    "# Groundness Checker 를 실행하여 평가\n",
    "request_input = {\n",
    "    \"context\": \"테디의 성별은 남자이며, 테디노트 유튜브 채널을 운영하고 있습니다.\",\n",
    "    \"answer\": \"테디는 여자다.\",\n",
    "}\n",
    "\n",
    "response = upstage_groundedness_check.invoke(request_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51544a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "\n",
    "def upstage_groundness_check_evaluator(run: Run, example: Example) -> dict:\n",
    "    # LLM 생성 답변, 정답 답변 가져오기\n",
    "    answer = run.outputs.get(\"answer\", \"\")\n",
    "    context = run.outputs.get(\"context\", \"\")\n",
    "\n",
    "    # Groundness 체크\n",
    "    groundedness_score = upstage_groundedness_check.invoke(\n",
    "        {\"answer\": answer, \"context\": context}\n",
    "    )\n",
    "    groundedness_score = groundedness_score == \"grounded\"\n",
    "\n",
    "    return {\"key\": \"groundness_score\", \"score\": int(groundedness_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd98f87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laptop_sam\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'GROUNDEDNESS-EVAL-15d34997' at:\n",
      "https://smith.langchain.com/o/8d57949a-053b-4992-8dd3-1ac178b342de/datasets/c32f8c4b-5e6c-4adc-81b0-fbe60afdddfb/compare?selectedSessions=56f80871-ec3d-42ce-8202-cde5c0717712\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:18,  3.67s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 실행\n",
    "experiment_results = evaluate(\n",
    "    upstage_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        upstage_groundness_check_evaluator,\n",
    "    ],\n",
    "    experiment_prefix=\"GROUNDEDNESS-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Upstage Groundness Checker 를 활용한 Hallucination 평가\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba82eb",
   "metadata": {},
   "source": [
    "# summary evaluators를 활용한 데이터셋 전체에 대한 종합 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513f678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def upstage_groundness_check_summary_evaluator(\n",
    "    runs: List[Run], examples: List[Example]\n",
    ") -> dict:\n",
    "    def is_grounded(run: Run) -> bool:\n",
    "        context = run.outputs[\"context\"]\n",
    "        answer = run.outputs[\"answer\"]\n",
    "        return (\n",
    "            upstage_groundedness_check.invoke({\"context\": context, \"answer\": answer})\n",
    "            == \"grounded\"\n",
    "        )\n",
    "\n",
    "    groundedness_scores = sum(1 for run in runs if is_grounded(run))\n",
    "    return {\"key\": \"groundness_score\", \"score\": groundedness_scores / len(runs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dddb84aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'GROUNDNESS_UPSTAGE_SUMMARY_EVAL-5993caed' at:\n",
      "https://smith.langchain.com/o/8d57949a-053b-4992-8dd3-1ac178b342de/datasets/c32f8c4b-5e6c-4adc-81b0-fbe60afdddfb/compare?selectedSessions=4982092d-9e3c-4222-bc1b-ae67ca42446b\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:16,  3.35s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가 실행\n",
    "experiment_result1 = evaluate(\n",
    "    upstage_chain,\n",
    "    data=dataset_name,\n",
    "    summary_evaluators=[\n",
    "        upstage_groundness_check_summary_evaluator,\n",
    "    ],\n",
    "    experiment_prefix=\"GROUNDNESS_UPSTAGE_SUMMARY_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Upstage Groundness Checker 를 활용한 Hallucination 평가\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae871c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
