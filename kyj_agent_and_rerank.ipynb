{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a462ccec",
   "metadata": {},
   "source": [
    "### Agent Tool + Save searched information to vector db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e7360dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_upstage import ChatUpstage, UpstageEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8bd74008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "upstage_api_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "\n",
    "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=25)\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"./SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 문서를 로드하고 분할합니다.\n",
    "split_docs = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58f11c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorStore를 생성합니다.\n",
    "embeddings = UpstageEmbeddings(api_key=upstage_api_key, model=\"embedding-query\")\n",
    "vector = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "vector.save_local(\"faiss_index_agent_rerank\")\n",
    "\n",
    "# Retriever를 생성합니다.\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9110c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector DB 로컬에 저장 후 로드 하는 예제 코드\n",
    "# # 파일 경로\n",
    "# index_path = \"faiss_index_rerank\"\n",
    "\n",
    "# # 벡터 스토어 생성 또는 로드\n",
    "# if os.path.exists(index_path):\n",
    "#     print(\"기존 FAISS 인덱스를 로드합니다.\")\n",
    "#     vector = FAISS.load_local(\n",
    "#         index_path, embeddings, allow_dangerous_deserialization=True\n",
    "#     )\n",
    "#     vector.add_documents(splits)\n",
    "# else:\n",
    "#     print(\"새로운 FAISS 인덱스를 생성합니다.\")\n",
    "#     vector = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "# # 인덱스 저장\n",
    "# vector.save_local(index_path)\n",
    "# retriever = vector.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c281d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
    "# k=6은 검색 결과를 6개까지 가져오겠다는 의미입니다\n",
    "search = TavilySearchResults(\n",
    "    max_results=3, include_domains=[\"naver.com\", \"google.com\", \"sports.news.naver.com\"]\n",
    ")\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"pdf_search\",  # 도구의 이름을 입력합니다.\n",
    "    description=\"use this tool to search information from the PDF document\",  # 도구에 대한 설명을 자세히 기입해야 합니다!!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2ec6a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAndStoreTool:\n",
    "    def __init__(self, search_tool, vectorstore, embedding_model, text_splitter):\n",
    "        self.search_tool = search_tool\n",
    "        self.vectorstore = vectorstore\n",
    "        self.embedding_model = embedding_model\n",
    "        self.text_splitter = text_splitter\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        # 1. 검색\n",
    "        search_results = self.search_tool.invoke(query)\n",
    "\n",
    "        # 2. Document 형식으로 변환\n",
    "        docs = [\n",
    "            Document(\n",
    "                page_content=item[\"content\"],\n",
    "                metadata={\n",
    "                    \"title\": item.get(\"title\", \"\"),\n",
    "                    \"url\": item.get(\"url\", \"\"),\n",
    "                    \"score\": item.get(\"score\", 0.0),\n",
    "                },\n",
    "            )\n",
    "            for item in search_results\n",
    "        ]\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        # 3. 벡터화 및 저장\n",
    "        self.vectorstore.add_documents(splits)\n",
    "        self.vectorstore.save_local(\"faiss_index_agent_rerank\")\n",
    "\n",
    "        return f\"Stored {len(splits)} documents from web search.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "131c814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구로 wrapping\n",
    "search_tool = Tool(\n",
    "    name=\"search_tool\",\n",
    "    func=SearchAndStoreTool(search, vector, embeddings, text_splitter).run,\n",
    "    description=\"Search information from web and store the results to the vector database.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457dede1",
   "metadata": {},
   "source": [
    "### rerank 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "292b0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "import torch\n",
    "\n",
    "# model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "# reranker = CrossEncoderReranker(model=model, top_n=3)\n",
    "reranker = CrossEncoder(\n",
    "    \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1737af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RerankTool:\n",
    "    def __init__(self, reranker, retriever):\n",
    "        self.reranker = reranker\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def __rerank__(self, query: str, top_k=3):\n",
    "        # docs = self.retriever.get_relevant_documents(query)\n",
    "        docs = self.retriever.invoke(query)\n",
    "        # 각 문서와 쿼리를 쌍으로 만들어 점수 계산\n",
    "        pairs = [(query, doc.page_content) for doc in docs]\n",
    "        scores = self.reranker.predict(pairs)\n",
    "\n",
    "        # 점수와 함께 문서를 묶어서 정렬\n",
    "        scored_docs = list(zip(scores, docs))\n",
    "        scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # top_k 문서만 선택\n",
    "        return [doc for _, doc in scored_docs[:top_k]]\n",
    "\n",
    "    def output(self, query: str):\n",
    "        top_docs = self.__rerank__(query)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in top_docs])\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca70de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구로 wrapping\n",
    "rerank_tool = Tool(\n",
    "    name=\"rerank_tool\",\n",
    "    func=RerankTool(reranker, retriever).output,\n",
    "    description=\"Search reranked information from vector database for final answer.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3acbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
    "# tools = [search, retriever_tool]\n",
    "tools = [search_tool, retriever_tool, rerank_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ccd44fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import ChatUpstage, UpstageEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatUpstage(model_name=\"solar-mini\")\n",
    "\n",
    "# Prompt 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"First, make sure to use the `pdf_search` tool for searching information from the PDF document.\"\n",
    "            \"If you can't find the information from the PDF document, you MUST use `search_tool` tool for searching information from the web.\"\n",
    "            \"Never answer a question based on your own knowledge without using tools.\"\n",
    "            \"Finally use `rerank_tool` to get information, before answering the question\"\n",
    "            \"After all, you must return answer about question.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ediso\\AppData\\Local\\Temp\\ipykernel_14048\\2276822396.py:2: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  context = rerank_tool(test_query)\n",
      "C:\\Users\\ediso\\AppData\\Local\\Temp\\ipykernel_14048\\4225406442.py:7: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = self.retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reranked Context ===\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "nIT 전문지 테크리퍼블릭 (TechRepublic) 은 온디바이스 AI가 주요 기술 트렌드로 부상했다며 , \n",
      "2024 년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2 를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel) 과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자 , ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스 ’ 공개, 2023.11.08.\n",
      "삼성전자 , ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12 월호\n",
      "10삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개\n",
      "n삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스 ’를 공개\n",
      "n삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로 , 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유KEY Contents\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스 , 온디바이스 작동 지원\n",
      "n삼성전자가 2023 년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스 ’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스 (Gauss) 의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며 , \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며 , 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는  \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며 , 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이 (code.i)’ 는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "nIT 전문지 테크리퍼블릭 (TechRepublic) 은 온디바이스 AI가 주요 기술 트렌드로 부상했다며 ,\n",
      "\n",
      "2023 년 12월호\n",
      "Ⅰ. 인공지능 산업 동향 브리프\n",
      " 1. 정책/법제 \n",
      "   ▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표  ························· 1\n",
      "   ▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의··························· 2\n",
      "   ▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언··························· 3\n",
      "   ▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각····································· 4\n",
      "   ▹ 미국 연방거래위원회 , 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출················· 5\n",
      "   ▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항··················································· 6\n",
      " \n",
      " 2. 기업/산업 \n",
      "   ▹ 미국 프런티어 모델 포럼, 1,000 만 달러 규모의 AI 안전 기금 조성································ 7\n",
      "   ▹ 코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개  ······································· 8\n",
      "   ▹ 알리바바 클라우드 , 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9\n",
      "   ▹ 삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n"
     ]
    }
   ],
   "source": [
    "# test_query = \"삼성전자의 생성형 AI 전략\"\n",
    "# context = rerank_tool(test_query)\n",
    "\n",
    "# print(\"=== Reranked Context ===\")\n",
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5e693aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# tool calling agent 생성\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# AgentExecutor 생성\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca7e154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `pdf_search` with `{'query': '2024년 한국 프로야구 플레이오프 진출한 4팀'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m행사명 행사 주요 개요\n",
      "CES 2024\n",
      "-미국 소비자기술 협회(CTA) 가 주관하는 세계 최대 가전·IT·소\n",
      "비재 전시회로 5G, AR&VR, 디지털헬스 , 교통·모빌리티 등 \n",
      "주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\n",
      "-CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며 , \n",
      "모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한 \n",
      "이번 전시에는 500곳 이상의 한국기업 참가 예정\n",
      "기간 장소 홈페이지\n",
      "2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\n",
      "AIMLA 2024\n",
      "-머신러닝 및 응용에 관한 국제 컨퍼런스 (AIMLA 2024) 는 \n",
      "인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 \n",
      "지식과  최신 연구 결과 공유\n",
      "-이론 및 실무 측면에서 인공지능 , 기계학습의 주요 분야를 \n",
      "논의하고 , 학계, 산업계의 연구자와 실무자들에게 해당 분\n",
      "야의 최첨단 개발 소식 공유\n",
      "기간 장소 홈페이지\n",
      "\n",
      "∙한편, 2023 년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해 \n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙오픈AI 창업자 그룹의 일원이었던 다리오 (Dario Amodei) 와 다니엘라 아모데이 (Daniela Amodei) \n",
      "남매가 2021 년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드 (Claude)’ LLM을 개발\n",
      "n아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인  오픈\n",
      "AI와 협력을 확대\n",
      "∙마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023 년 1월 추가로 100억 달러를 \n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며 , 오픈AI는 마이크로소프트의 애저(Azure) \n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "\n",
      "2024 년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2 를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel) 과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자 , ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스 ’ 공개, 2023.11.08.\n",
      "삼성전자 , ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      "기간 장소 홈페이지\n",
      "2024.1.27~28 덴마크 , 코펜하겐https://ccnet2024.org/aimla\n",
      "/index\n",
      "AAAI Conference \n",
      "on Artificial \n",
      "Intelligence\n",
      "-AI 발전 협회 컨퍼런스 (AAAI) 는 AI 연구를 촉진하고 , AI 분야 \n",
      "연구원 , 실무자 , 과학자 , 학생 및 공학자 간 교류의 기회 제공\n",
      "-컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, \n",
      "워크숍 , 튜토리얼 , 포스터 세션, 주제 발표, 대회, 전시 프\n",
      "로그램 등 진행   \n",
      "기간 장소 홈페이지\n",
      "2024.2.20~27 캐나다 , 밴쿠버https://aaai.org/aaai-confere\n",
      "nce/\n",
      "Ⅱ. 주요 행사 일정\n",
      "\n",
      "AD&D 는 향후 5년간 카테고리 중 가장 높은 38.7% 의 연평균 성장률이 예상됨\n",
      "nIDC에 따르면 경제적 불확실성과 시장 역학의 변화에도 AI와 자동화 기술에 대한 기업들의 투자 \n",
      "의지는 확고하며 , 기업들은 AI 도입이 사업 성공과 경쟁우위에 필수적이라고 인식\n",
      "∙IDC 설문조사에 따르면 향후 12개월 동안 응답자의 3분의 1은 기업이 특정 사용 사례나 응용 영역에서 \n",
      "외부 AI 소프트웨어의 구매를 고려하거나 외부 AI 소프트웨어와 내부 자원의 결합을 고려\n",
      "n한편, AI 소프트웨어 시장에 포함되지 않는 생성 AI 플랫폼과 애플리케이션은 2027 년까지 283억 \n",
      "달러의 매출을 창출할 전망 \n",
      "☞ 출처 : IDC, IDC Forecasts Revenue for Artificial Intelligence Software Will Reach $279 Billion Worldwide in \n",
      "2027, 2023.10.31.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_tool` with `2024년 한국 프로야구 플레이오프 진출한 4팀`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mStored 5 documents from web search.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `rerank_tool` with `2024년 한국 프로야구 플레이오프 진출한 4팀`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m출처 KT위즈\n",
      "\n",
      "출처 KT위즈\n",
      "\n",
      "2024 프로야구 일정 와일드카드 결정전 [...] 2024 프로야구 포스트시즌 일정의 그 첫 일정은\n",
      "4위 두산 베어스와 5위 KT 위즈와의 경기였습니다.\n",
      "첫 경기인 10월 2일 4:0 오늘 경기 1:0으로\n",
      "4위 두산 베어스를 꺾고 5위 KT 위즈가\n",
      "KBO 준플레이오프에 진출하게 되었습니다.\n",
      "5위가 4위를 이긴건 KBO 와일드카드 결정전 시작하고\n",
      "처음 있는 일이었습니다. KT위즈 새역사를 쓰다.\n",
      "KT위즈는 LG 트윈스와\n",
      "10월 5일 잠실에서 KBO준플레이오프\n",
      "1차전에서 만나게 됩니다.\n",
      "\n",
      "출처 LG 트윈스\n",
      "\n",
      "출처 LG 트윈스\n",
      "​\n",
      "\n",
      "\n",
      "출처 KT위즈\n",
      "\n",
      "출처 LG 트윈스\n",
      "​\n",
      "\n",
      "\n",
      "출처 KT위즈\n",
      "\n",
      "2024 KBO 준플레이오프 경기 일정 및 프로야구 예매 안내 [...] #보미블로그 #KBO #2024KBO #KBO리그 #포스트시즌 #가을야구 #와일드카드 #준플레이오프 #플레이오프 #한국시리즈 #KT위즈 #두산베어스 #LG트윈스 #삼성라이온즈 #기아타이거즈 #프로야구 #야구 #KBO포스트시즌 #가을야구 #프로야구와일드카드 #KBO준플레이오프 #KBO플레이오프 #프로야구한국시리즈 #프로야구포스트시즌 #야구랜선응원 #프로야구일정 #프로야구순위 #국내야구일정 #한국프로야구 #프로야구예매 #포스트시즌예매\n",
      "\n",
      "... 플레이오프에 진출한 삼성은. 디펜딩 챔피언 LG 트윈스를. 3승 1패로 꺾고 한국시리즈 진출을 확정 지었습니다. 2024년 KBO 한국시리즈는. KIA 타이거즈\u001b[0m\u001b[32;1m\u001b[1;3m2024년 한국 프로야구 플레이오프 진출한 4팀은 두산 베어스, KT 위즈, LG 트윈스, 삼성 라이온즈입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "2024년 한국 프로야구 플레이오프 진출한 4팀은 두산 베어스, KT 위즈, LG 트윈스, 삼성 라이온즈입니다.\n"
     ]
    }
   ],
   "source": [
    "# 질의에 대한 답변을 출력\n",
    "\n",
    "result = agent_executor.invoke(\n",
    "    {\"input\": \"2024년 한국 프로야구 플레이오프 진출한 4팀을 검색하여 알려주세요.\"}\n",
    ")\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37cba5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `pdf_search` with `{'query': '네이버가 자체 개발한 생성형 AI'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mSPRi AI Brief |  \n",
      "2023-12 월호\n",
      "10삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개\n",
      "n삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스 ’를 공개\n",
      "n삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로 , 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유KEY Contents\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스 , 온디바이스 작동 지원\n",
      "n삼성전자가 2023 년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스 ’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스 (Gauss) 의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며 ,\n",
      "\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항··················································· 6\n",
      " \n",
      " 2. 기업/산업 \n",
      "   ▹ 미국 프런티어 모델 포럼, 1,000 만 달러 규모의 AI 안전 기금 조성································ 7\n",
      "   ▹ 코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개  ······································· 8\n",
      "   ▹ 알리바바 클라우드 , 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9\n",
      "   ▹ 삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개 ··························································· 10\n",
      "\n",
      "2024 년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2 를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel) 과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자 , ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스 ’ 공개, 2023.11.08.\n",
      "삼성전자 , ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      "∙한편, 2023 년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해 \n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙오픈AI 창업자 그룹의 일원이었던 다리오 (Dario Amodei) 와 다니엘라 아모데이 (Daniela Amodei) \n",
      "남매가 2021 년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드 (Claude)’ LLM을 개발\n",
      "n아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인  오픈\n",
      "AI와 협력을 확대\n",
      "∙마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023 년 1월 추가로 100억 달러를 \n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며 , 오픈AI는 마이크로소프트의 애저(Azure) \n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "\n",
      "다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\n",
      "∙생성 AI 개발에 필요한 컴퓨팅과 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼 (PAI), \n",
      "데이터베이스 솔루션 , 컨테이너 서비스와 같은 클라우드 신제품도 발표\n",
      "n알리바바 클라우드는 AI 개발을 촉진하기 위해 올해 말까지 720억 개 매개변수를 가진 통이치엔원  \n",
      "모델을 오픈소스화한다는 계획도 공개\n",
      "☞ 출처 : Alibaba Cloud, Alibaba Cloud Launches Tongyi Qianwen 2.0 and Industry-specific Models to Support \n",
      "Customers Reap Benefits of Generative AI, 2023.10.31.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_tool` with `네이버가 자체 개발한 생성형 AI`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mStored 3 documents from web search.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `rerank_tool` with `네이버가 자체 개발한 생성형 AI`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m네이버가 자체 개발한 생성형 AI 모델인 하이퍼클로바X는 약 23년간 네이버가 축적한 방대한 양의 한국어 데이터를 학습해 가장 자연스러운 한국어\n",
      "\n",
      "네이버는 하이퍼클로바X 라는 생성형AI 모델을 자체 개발했습니다. 네이버가 23년간 축적한 한글로 된 데이터가 이 모델의 학습을 담당했습니다. 23\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12 월호\n",
      "10삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개\n",
      "n삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스 ’를 공개\n",
      "n삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로 , 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유KEY Contents\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스 , 온디바이스 작동 지원\n",
      "n삼성전자가 2023 년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스 ’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스 (Gauss) 의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며 ,\u001b[0m\u001b[32;1m\u001b[1;3m네이버가 자체 개발한 생성형 AI 모델인 하이퍼클로바X는 약 23년간 네이버가 축적한 방대한 양의 한국어 데이터를 학습해 가장 자연스러운 한국어 생성형 AI 모델입니다. 네이버는 하이퍼클로바X 라는 생성형AI 모델을 자체 개발했습니다. 네이버가 23년간 축적한 한글로 된 데이터가 이 모델의 학습을 담당했습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "네이버가 자체 개발한 생성형 AI 모델인 하이퍼클로바X는 약 23년간 네이버가 축적한 방대한 양의 한국어 데이터를 학습해 가장 자연스러운 한국어 생성형 AI 모델입니다. 네이버는 하이퍼클로바X 라는 생성형AI 모델을 자체 개발했습니다. 네이버가 23년간 축적한 한글로 된 데이터가 이 모델의 학습을 담당했습니다.\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.invoke(\n",
    "    {\"input\": \"네이버가 자체 개발한 생성형 AI에 대해서 알려줘.\"}\n",
    ")\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5618a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
